---
title: |
       | Computation of Large Spatial Datasets with the M function
author:
  - name: "Eric Marcon"
    authsuperscript: 1 \orcidlink{0000-0002-5249-321X}
  - name: "Florence Puech"
    authsuperscript: 2 \orcidlink{0000-0002-5279-6878}
affiliation:
  - affsuperscript: 1
    dptuniv: "AgroParisTech, UMR AMAP, CIRAD, CNRS, INRAE, IRD, Univ Montpellier, Montpellier, France."
  - affsuperscript: 2
    dptuniv: "Université Paris-Saclay, INRAE, AgroParisTech, Paris-Saclay Applied Economics, F-91120 Palaiseau, France."
corrauthor:
  email: eric.marcon@agroparistech.fr
abstract: >
  Increasing access to large geo-referenced datasets, coupled with the development of computing power, has encouraged the search for suitable spatial statistical tools.
  Distance-based methods have been extensively developed in several scientific fields to detect spatial concentration, dispersion or independence of entities at any distance and without any bias.
  Recently, @Tidu2023 highlighted the qualities of Marcon and Puech's *M* function, a relative distance-based measure, and also expressed reservations about the computation time required.
  Herein, we propose a methodology that specifies the processing of large spatialized datasets with the *M* function using R software.
  The computational performance of *M* was conducted using two methods: (i) a precise evaluation of the computational time and memory requirements for geo-referenced data was conducted using the *dbmss* package in R via performance tests, and (ii) based on @Tidu2023, we considered an approximation of the geographical positions of the entities.
  The deterioration extent of the *M* results was estimated and discussed as the gains it provides in computation time.
  We provided evidence that the individual location approximation generated information loss at substantially small distances, implying a trade-off between the smallest distance at which spatial interactions could be detected and computing performance. 
  The R code used in the article is given for the reproducibility of our results.
keywords: [Distance-based method, M-function, Performance test, R Package dbmss]
journalinfo: "Preprint"
date: "`r format(Sys.time(), '%B %d, %Y')`"
archive: "`r format(Sys.time(), '%B %d, %Y')`"
keywordlabel: Keywords
corrauthorlabel: Corresponding author
url: https://EricMarcon.github.io/MLargeDataSets/
github-repo: EricMarcon/MLargeDataSets
lang: en-GB
bibliography: references.bib
biblio-style: chicago
csl: apa
toc-depth: 3
fontsize: 10pt
urlcolor: blue
always_allow_html: yes
csquotes: true
output:
  rmdformats::downcute:
    use_bookdown: yes
    lightbox: yes
    toc_depth: 3
  bookdown::pdf_book:
    template: latex/template.tex
    citation_package: natbib
    latex_engine: xelatex
    keep_tex: no
  bookdown::word_document2:
     reference_docx: "images/template.docx"
     number_sections: false
---

```{r DoNotModify, include=FALSE}
### Utilities. Do not modify.
# Installation of packages if necessary
InstallPackages <- function(Packages) {
  InstallPackage <- function(Package) {
    if (!Package %in% installed.packages()[, 1]) {
      install.packages(Package, repos = "https://cran.rstudio.com/")
    }
  }
  invisible(sapply(Packages, FUN = InstallPackage))
}

# Basic packages
InstallPackages(c("bookdown", "formatR", "ragg", "magick", "kableExtra"))

# Chunk font size hook: allows size='small' or any valid Latex font size in chunk options
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r Options, include=FALSE}
### Customized options for this document
# Add necessary packages here
Packages <- c(
  "tidyverse", 
  "spatstat", 
  "dbmss", 
  "pbapply", 
  "plyr", 
  "microbenchmark", 
  "profmem", 
  "gridExtra",
  "benchmarkme"
)
# Install them
InstallPackages(Packages)

# knitr options
knitr::opts_chunk$set(
  cache =   TRUE,     # Cache chunk results
  include = FALSE,    # Show/Hide chunks
  echo =    FALSE,    # Show/Hide code
  warning = FALSE,    # Show/Hide warnings
  message = FALSE,    # Show/Hide messages
  # Figure alignment and size
  fig.align = 'center', out.width = '100%',
  # Graphic devices (ragg_png is better than standard png)
  dev = c("ragg_png", "pdf"),
  # Code chunk format
  tidy = FALSE, tidy.opts = list(blank = FALSE, width.cutoff = 50),
  size = "scriptsize", knitr.graphics.auto_pdf = TRUE
  )
options(width = 50)

# ggplot style
library("tidyverse")
theme_set(theme_bw(base_size = 14))
theme_update(
  panel.background = element_rect(fill = "transparent", colour = NA),
  plot.background = element_rect(fill = "transparent", colour = NA)#,
  # legend.text = element_text(size = 14),
  # axis.text.x = element_text(size = 13),
  # axis.text.y = element_text(size = 13)
)
knitr::opts_chunk$set(dev.args = list(bg = "transparent"))

# Random seed
set.seed(973)
```


# Data simulation

The datasets we consider in this article were obtained by simulation.
The R code is given in the appendix, which allows perfect reproducibility of the examples treated.

## Drawing the points

```{r}
#| label: ParamsCSRCode
library("tidyverse")
library("spatstat")
library("dbmss")

par_points_nb <- 10000#0
par_case_ratio <- 1/20
par_size_gamma_shape <- 0.95
par_size_gamma_scale  <- 10
```

A set of points is drawn using the Poisson process (whose expectation of the number of points is `r format(as.numeric(par_points_nb), scientific=FALSE, big.mark=",")`) in a square window of side one.
Each point is assigned a qualitative mark: "Case" or "Control".
`r (1 - par_case_ratio)* 100`% of points are Controls.
Additionally, `r par_case_ratio * 100`% are Cases, whose spatial structure is studied.
The weight of the points is drawn from a gamma distribution with free shape and scale parameters.

```{r}
#| label: XcsrCode
X_csr <- function(
    points_nb,
    case_ratio = par_case_ratio,
    size_gamma_shape = par_size_gamma_shape,
    size_gamma_scale = par_size_gamma_scale) {
  points_nb %>% 
    runifpoint() %>% 
    as.wmppp() ->
    X
  cases_nb <- round(points_nb *  case_ratio)
  controls_nb <- points_nb - cases_nb
  c(rep("Control", controls_nb), rep("Case", cases_nb)) %>% 
    as.factor() ->
    X$marks$PointType
  rgamma(
    X$n, 
    shape = size_gamma_shape, 
    scale = size_gamma_scale
  ) %>% 
    ceiling() ->
    X$marks$PointWeight
  X
}

# Example
X <- X_csr(par_points_nb)
# Map the cases
autoplot(X[X$marks$PointType == "Case"])
```

In this example, the drawing of Controls points is completely random (*complete spatial randomness*: CSR), i.e., there is no simulation of attraction or dispersion.
On the contrary, the spatial distribution of Cases is aggregated, which means that Cases are spatially concentrated (like clusters).
Practically, sets of aggregated points are drawn in a @Matern1960 process.

```{r}
#| label: ParamsMaternCode
# Expected number of clusters
par_kappa <- 20
# Cluster radius
par_scale <-  0.1
```

(ref:XMatern) Random drawing of a set of points where the Cases (red) are aggregated and the Controls (blue) are distributed completely randomly. The size of the points is proportional to their weight.

```{r}
#| label: XMaternFig
#| include: true
#| fig.cap: "(ref:XMatern)"
X_matern <- function(
    points_nb,
    case_ratio = par_case_ratio,
    kappa = par_kappa,
    scale = par_scale,
    size_gamma_shape = par_size_gamma_shape,
    size_gamma_scale = par_size_gamma_scale) {
  cases_nb <- round(points_nb *  case_ratio)
  controls_nb <- points_nb
  # CSR controls
  controls_nb %>% 
    runifpoint() %>% 
    superimpose(
      # Matern cases
      rMatClust(
        kappa = kappa, 
        scale = scale, 
        mu = cases_nb / kappa
      ) 
    ) %>% 
    as.wmppp() ->
    X
  # Update the number of cases
  cases_nb <- X$n - controls_nb
  c(rep("Control", controls_nb), rep("Case", cases_nb)) %>% 
    as.factor() ->
    X$marks$PointType
  rgamma(
    X$n, 
    shape = size_gamma_shape, 
    scale = size_gamma_scale
  ) %>% 
    ceiling() ->
    X$marks$PointWeight
  X
}

# Example
X <- X_matern(par_points_nb)
# Map the cases
autoplot(X) + 
  scale_size(range = c(0, 3))
```

Cases shown in Figure \@ref(fig:XMaternFig) indicate visible aggregates.
Controls are distributed completely randomly.
A careful analysis of Figure \@ref(fig:XMaternFig) shows a limited number of tiny white spaces on the square window, indicating locations with no points (whatever the type).
The scarcity of empty spaces is because of the high number of simulated points.

### Strauss

(ref:XStrauss) Random drawing of a set of points where the Cases (red) follow a Strauss hard-core process and the Controls (blue) are distributed completely randomly. The size of the points is proportional to their weight.

```{r}
#| label: XStraussFig
#| include: true
#| fig.cap: "(ref:XStrauss)"
X_strauss <- function(
    points_nb,
    case_ratio = par_case_ratio,
    gamma = .7, r = 0.3, hc = 0.03,
    size_gamma_shape = par_size_gamma_shape,
    size_gamma_scale = par_size_gamma_scale) {
  cases_nb <- round(points_nb *  case_ratio)
  controls_nb <- points_nb - cases_nb
  # CSR controls
  controls_nb %>% 
    runifpoint() %>% 
    superimpose(
      # Simulation parfaite, mais le nombre de points est incontrôlable
      # rStraussHard(
      #   beta = 100,
      #   gamma = 0.5,
      #   R = 0.2,
      #   H = 0.05
      # )
      # Srauss cases
      rmh(
        model = list(
          # Strauss hard core
          cif = "straush",
          # beta inutilisé, gamma = interaction, r = distance max, hc = hard core
          par = list(beta = 1, gamma = gamma, r = r, hc = hc),
          w = c(0, 1, 0, 1)
        ),
        start = list(n.start = cases_nb),
        # p = 1 fixe le nombre de points, nrep est le nombre de pas
        control = list(p = 1, nrep = 1E6, nverb = 0)
      )
    ) %>% 
    as.wmppp() ->
    X
  # Update the number of cases
  cases_nb <- X$n - controls_nb
  c(rep("Control", controls_nb), rep("Case", cases_nb)) %>% 
    as.factor() ->
    X$marks$PointType
  rgamma(
    X$n, 
    shape = size_gamma_shape, 
    scale = size_gamma_scale
  ) %>% 
    ceiling() ->
    X$marks$PointWeight
  X
}

# Example
X <- X_strauss(par_points_nb)
# Map the cases
autoplot(X) + 
  scale_size(range = c(0, 3))
```


## Gridding the space

The simulation of the Cases obtained by the Matérn process is considered and the window is split into a 20 x 20 square grid.
This partition simulates the approximation of the position of the points of an administrative unit to the position of its center.
Moreover, this grid size is consistent with that of @Tidu2023, which facilitates a comparison of our results.
The choice of the optimal level of the grid remains an open question, as @Arbia2021 noticed (p.109): "*Unfortunately, the choice of the partitioning scheme is usually arbitrary and an optimal criterion to guide this choice is not available*."

```{r}
#| label: ParamsPartitionsCode
# Number of rows and columns
par_partitions <- 20
```

```{r}
#| label: group_pointsCode
# Group points into cells
group_points <- function(X, partitions = par_partitions) {
  X %>%
    with(tibble(
      x, 
      y, 
      PointType = marks$PointType, 
      PointWeight = marks$PointWeight)
    ) %>% 
    mutate(
      x_cell = ceiling(x * partitions) / partitions - 1 / 2 / partitions,
      y_cell = ceiling(y * partitions) / partitions - 1 / 2 / partitions,
      .keep = "unused"
    ) %>%
    rename(x = x_cell, y = y_cell) %>% 
    as.wmppp(window = X$window, unitname = X$window$units) %>% 
    rjitter()
}
# Group points and merge them
group_points_to_plot <- function(X, partitions = par_partitions) {
  X %>%
    with(tibble(
      x, 
      y, 
      PointType = marks$PointType, 
      PointWeight = marks$PointWeight)
    ) %>% 
    mutate(
      x_cell = ceiling(x * partitions) / partitions - 1 / 2 / partitions,
      y_cell = ceiling(y * partitions) / partitions - 1 / 2 / partitions
    ) %>%
    group_by(PointType, x_cell, y_cell) %>% 
    summarise(n = n(), PointWeight = sum(PointWeight)) %>% 
    rename(x = x_cell, y = y_cell) %>% 
    as.wmppp(window = X$window, unitname = X$window$units)
}
```

The approximated position of points is depicted on the map presented in Figure \@ref(fig:GroupedFig).
Each cell comprises only one point of each type, whose weight is the sum of the weights of the individual points.

(ref:Grouped) Repositioning of points in an arbitrary grid. The absence of Cases in a cell is easily detected (single-color blue dot), as is the strong presence of Cases in a cell (two-color dot, but predominantly red).

```{r}
#| label: GroupedFig
#| include: true
#| fig.cap: "(ref:Grouped)"
X %>% group_points_to_plot() %>% autoplot(alpha = 0.5)
```

*M* values can be calculated from the original point set or its approximation.

\newpage

# Computing *M* using the *dbmss* package

```{r}
#| label: ParamsrCode
r <- c((0:9) / 100, (2:10) / 20)
```

## Necessary data


## Point pattern

The `Mhat()` function in the *dbmss* package is used to estimate the *M* function.
The theoretical reference value for *M* is one, as this function relates the proportion of Cases up to a distance $r$ to that observed across the entire window.
The aggregation of Cases will be highlighted by values of *M* \> 1 (the relative presence of Cases is greater locally than across the entire window) and the dispersion of Cases by values \< 1.
The Euclidean distance is used to estimate the distance between points.

Figure \@ref(fig:MFig) shows that *M* detects an agglomeration of Cases, which is in line with the simulation of this type of point (Controls having a completely random location on the window).
The advantage of a function based on distances is clearly visible: for any distance, the level of spatial concentration is precisely estimated.
It enables the detection of distances at which the attraction phenomena occur and are the most important (for functions whose values can be compared at different radii, such as *M*).
In addition to estimating the *M* function, the `Menvelope()` function can be used to calculate its global confidence interval [@Duranton2005] under the null hypothesis of random point location.
The confidence interval of the null hypothesis is centered on one, and is narrow because of the large dataset.
Lastly, the necessary simulations can be parallelized to save time.

(ref:M) Value of *M* as a function of the distance from the reference point. The 95% confidence envelope, obtained from 100 simulations, appears in gray and is centered on the value of one.

```{r}
#| label: MFig
#| include: true
#| fig.cap: "(ref:M)"
X %>% 
  MEnvelope(r = r, ReferenceType = "Case", Global = TRUE) %>% 
  autoplot() +
  theme(
    legend.position = c(0.7, 0.75), 
    legend.background = element_blank()
  )
```


(ref:Mgrouped) Value of *M* after grouping.

```{r}
#| label: MgroupedFig
#| include: true
#| fig.cap: "(ref:Mgrouped)"
X %>% 
  group_points() %>% 
  MEnvelope(r = r, ReferenceType = "Case", Global = TRUE) %>% 
  autoplot() +
  theme(
    legend.position = c(0.7, 0.75), 
    legend.background = element_blank()
  )
```



# Computational performance

```{r}
#| label: XtoMCode
# Compute M
X_to_M <- function(X) {
  X %>% 
    Mhat(r = r, ReferenceType = "Case") %>% 
    pull("M")    
}
```

The use of *M* to characterize the spatial structure of large sets of points might be limited by its computing time or the memory required.
In this section, we investigate these two potential limitations.

# Effects of approximating the position of points

```{r}
#| label: ParamsSimsCode
simulations_n <- 20
```

## Two main effects

Unambiguously, approximating the position of the points generates a loss of information: in each grid cell, the distance between all the points is set to zero, and the distance between two points in different cells is approximated using the distance between the centroids of the two cells.
The first consequence is that **no spatial structure in each cell can be detected because the information is completely lost.** The merits of any distance-based methods are detecting the exact geographic scale(s) where any patterns of aggregation, dispersion or independence of points exist.
Grouping points at the centroid of cells erases any spatial structure under the size grid.
The same limit under the size grid is faced for distributions with multiple patterns of points (that is a coexistence of attraction and dispersion of points depending on the distance considered).
@Tidu2023 gathered an average of 320 points in every 377 municipalities of Sardinia.
However, the local structure of these points was overlooked.
Moreover, we suspect **bias in *M* estimation based on a scale of the order of the magnitude of the size of the cells**, which should decrease with distance, when the relative size of the cells becomes negligible.

## Test setting

The effect of the location approximation is tested on a set of aggregated points, similar to the real @Tidu2023 data, and on a completely random point pattern.
Both comprise 100,000 points such that groups include 250 points (100,000 points divided by 400 groups) on average.

```{r}
#| label: XList
# Number of points for comparison simulations
par_points_comp_nb <- 1E4
# Simulate Matérn point patterns
X_strauss_list <- replicate(
  simulations_n, 
  expr = X_strauss(par_points_comp_nb), 
  simplify = FALSE
)
# Group points
X_strauss_grouped_list <- lapply(
  X_strauss_list, 
  FUN = group_points, 
  partitions = par_partitions
)
```

`r simulations_n` sets of completely random and of aggregated points (`r format(as.numeric(par_points_nb), scientific=FALSE, big.mark=",")` points with `r par_case_ratio * 100`% of Cases) were simulated.
The exact calculation and the calculation on the grid points were performed on each set of points to evaluate the effect of the approximation.

```{r}
#| label: MCompare
library("pbapply")
# Compute M
if (file.exists("data/MCompare.RData")) {
  # Do not compute if it has been saved before
  load("data/MCompare.RData")
} else {
  M_strauss_original <- pbsapply(X_strauss_list, FUN = X_to_M)
  M_strauss_grouped <- pbsapply(X_strauss_grouped_list, FUN = X_to_M)
  save(
    M_strauss_original, M_strauss_grouped,
    file = "data/MCompare.RData"
  )
}
```

(ref:Mapprox) Average estimate of *M* from the exact position of the points compared with the values obtained by grouping the points for CSR (a) and Matérn (b) point patterns.

```{r}
#| label: MapproxFig
#| include: true
#| fig.asp: 0.5
#| fig.cap: "(ref:Mapprox)"
#| fig.env: "figure*"
#| out.extra: ""

# Figure: exact and grouped M(r)
Mapproxfig <- function(M_original, M_grouped, tag) {
  tibble(
    r,
    Exact = rowMeans(M_original), 
    Grouped = rowMeans(M_grouped)
  ) %>% 
    pivot_longer(
      cols = !r,
      names_to = "M",
      values_to = "value"
    ) %>% 
    ggplot(aes(x = r, y = value, color = M, shape = M, linetype  = M)) +
    geom_line() +
    geom_point() +
    labs(x = "Distance", y = "M", tag = tag) +
    theme(
      legend.position = c(0.75, 0.8),
      legend.background = element_blank(),
      legend.text = element_text(size = 10)
    ) 
}

# Plot
  Mapproxfig(M_strauss_original, M_strauss_grouped, "b")
```

## Results

The mean values of the estimates of *M* are presented in Figure \@ref(fig:MapproxFig).
The size of the grid cells is equal to `r 1/par_partitions`.
All neighbors at distances less than this threshold are placed at zero distance.
The estimate of the corresponding *M* function (Grouped *M*) is constant in that case, up to this threshold.
When the actual point pattern is not structured, some artifactual aggregation is generated at a small scale.
In contrast, the local aggregation of the Matérn pattern is underestimated.
Figure \@ref(fig:MapproxFig) shows that at substantially short distances the grouped *M* plot is below the exact *M* plot obtained using the actual position of points.

@Tidu2023 tested the effect of grouping the points by the correlation between exact and approximated *M* values.
We refrained from following them because the main source of variation of the grouped-point *M* values is that of the grouping itself: when the number of points per group is small, groups considerably vary between simulations, and the correlation is weak.
It increases with the size of the data (an illustration is given in the appendix).
A substantially high correlation does not exclude systematic errors.
Therefore it is not considered an appropriate statistic here.

(ref:MCompare) p-values to reject the null hypothesis (H0) of independence of the point locations tested by the *M* function. The colors of the curves represent CSR or aggregated point patterns. Solid lines provide the exact p-values of *M*, and dotted lines provide the values estimated on grouped point patterns. The horizontal, dotted line corresponds to the significance threshold, i.e., 97.5%, to reject H0 in a 5% risk-level two-tailed test.

```{r}
#| label: MCompareFig
#| include: true
#| fig.cap: "(ref:MCompare)"

# Function to calculate the departure of the grouped point pattern M p-value
# against H0 from that of the real point pattern
p_departure <- function(
    X_list,
    M_simulations = simulations_n,
    verbose = interactive()
  ) {
  # Group the points
  X_grouped_list <- lapply(
    X_list,
    FUN = group_points,
    partitions = par_partitions
  )
  # Prepare arrays to save the results
  quantiles_exact <-
    quantiles_grouped <-
    matrix(NA, nrow = length(r) - 1, ncol = simulations_n)
  for (pp_i in seq_len(simulations_n)) {
    # Iterate across the point patterns
    if (verbose) cat("Point pattern", pp_i, "of", simulations_n,"\n")
    # Calculate M with simulations
    envelope_exact <- MEnvelope(
      X_list[[pp_i]],
      r = r,
      NumberOfSimulations = M_simulations,
      ReferenceType = "Case",
      parallel = TRUE,
      verbose = FALSE,
    )
    # Individual simulations are in an attribute.
    # Extract them in a dataframe, delete the first row (distances)
    # Each column contains M(r) for a simulation
    sims_exact <- as.data.frame(attr(envelope_exact, "simfuns"))[, -1]
    # Quantiles of each M(r) in the simulations
    quantiles_exact[, pp_i] <- sapply(
      # Remove distance 0
      seq_along(r)[-1],
      FUN = function(r_i) {
        # Quantile function of the simulated M(r)
        ecdf(as.numeric(sims_exact[r_i, ]))(envelope_exact$obs[r_i])
      }
    )
    # M grouped, idem
    envelope_grouped <- MEnvelope(
      X_grouped_list[[pp_i]],
      r = r,
      NumberOfSimulations = M_simulations,
      ReferenceType = "Case",
      parallel = TRUE,
      verbose = FALSE,
    )
    sims_grouped <- as.data.frame(attr(envelope_grouped, "simfuns"))[, -1]
    quantiles_grouped[, pp_i] <- sapply(
      # Remove distance 0
      seq_along(r)[-1],
      FUN = function(r_i) {
        # Quantile function of the simulated M(r)
        ecdf(as.numeric(sims_grouped[r_i, ]))(envelope_grouped$obs[r_i])
      }
    )
  }
  return(
    tibble(
      Exact = rowMeans(quantiles_exact),
      Grouped = rowMeans(quantiles_grouped),
    )
  )
}

if (file.exists("data/MCompareFig.RData")) {
  # Do not compute if it has been saved before
  load("data/MCompareFig.RData")
} else {
  # Parallelize M simulations
  library("doFuture")
  plan(multisession)
  departure_strauss <- p_departure(X_strauss_list)
  plan(sequential)
  save(
    departure_strauss,
    file = "data/MCompareFig.RData"
  )
}
  
# Plot the p-values
  departure_strauss %>% 
    mutate(Pattern = "Strauss", Distance = r[-1]) %>% 
  pivot_longer(Exact:Grouped) %>% 
  ggplot() +
  geom_line(aes(x = Distance, y = value, color = Pattern, linetype = name)) +
  geom_hline(yintercept = c(0.025, .975), linetype = 2) +
  labs(color = "Method", y = "p-value")
```

We chose the mentioned test.
The *M* function is basically used as a test against the independence of point locations.
To assess the impact of grouping the points on the test result, Figure \@ref(fig:MCompareFig) shows its average p-value, computed among `r simulations_n` simulations of each point pattern.
At each distance, the *M* value is compared with that obtained with point patterns simulated based on the null hypothesis, which is rejected if the actual value is outside of the 95% central quantiles of the simulations.

In the case of CSR, the p-value to reject independence around 50%, regardless of the distance, and whether the points are grouped or not.
In the case of aggregated patterns, the null hypothesis is rejected correctly when the points are grouped.
At small scale, below the size of the cells, *M* values are actually that of the cell size: the test is correct because the point process we used is aggregated at all scales.
The point pattern might have been repulsive at the small scale, but this information is destroyed by grouping the points: *M* and their p-values are not reliable below the size of the cells.

**Since all information below the grid size is lost, the approximation might or might not be acceptable depending on the research question and the spatial scale at which interactions occur. Above the grid size, the *M* function is less affected by the approximation and the gap becomes rapidly negligible**.


# Appendix {.unnumbered}

R code is available at the following address: <https://ericmarcon.github.io/MLargeDataSets/Appendix.pdf>

# Acknowledgments {.unnumbered}

Eric Marcon benefited from an 'Investissement d’Avenir' grant managed by the Agence Nationale de la Recherche (LABEX CEBA, ref. ANR-10-LBX-25) and Florence Puech gratefully acknowledges financial support from INRAE.
The authors thank participants of the SEW 2025 and especially Nardelli Vincenzo for helpful advice.

`r if (!knitr::is_latex_output()) '# References {-}'`
